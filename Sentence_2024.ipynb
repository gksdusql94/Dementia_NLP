{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "NCHdB-h6R-W4",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NCHdB-h6R-W4",
        "outputId": "33445be2-d076-4556-d9df-d159aa232765"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "from google.colab import drive\n",
        "\n",
        "drive.mount('/content/drive')\n",
        "os.chdir(\"/content/drive/MyDrive/OneDrive/DementiaBank/Pitt/Pitt/Dementia/sentence\") #google data dir"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "96rOs1Th7Fkc",
      "metadata": {
        "id": "96rOs1Th7Fkc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a77928db-1bf8-47e9-965d-9a005bedae2d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.11/dist-packages (4.47.1)\n",
            "Requirement already satisfied: sentence-transformers in /usr/local/lib/python3.11/dist-packages (3.3.1)\n",
            "Requirement already satisfied: spacy in /usr/local/lib/python3.11/dist-packages (3.7.5)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (1.26.4)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (2.2.2)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (2.5.1+cu124)\n",
            "Requirement already satisfied: openai in /usr/local/lib/python3.11/dist-packages (1.59.9)\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.11/dist-packages (3.9.1)\n",
            "Requirement already satisfied: gensim in /usr/local/lib/python3.11/dist-packages (4.3.3)\n",
            "Requirement already satisfied: soundfile in /usr/local/lib/python3.11/dist-packages (0.13.1)\n",
            "Requirement already satisfied: librosa in /usr/local/lib/python3.11/dist-packages (0.10.2.post1)\n",
            "Collecting contractions\n",
            "  Downloading contractions-0.1.73-py2.py3-none-any.whl.metadata (1.2 kB)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from transformers) (3.17.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.24.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.27.1)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from transformers) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2024.11.6)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from transformers) (2.32.3)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.21.0)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.5.2)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.11/dist-packages (from transformers) (4.67.1)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.11/dist-packages (from sentence-transformers) (1.6.1)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.11/dist-packages (from sentence-transformers) (1.13.1)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.11/dist-packages (from sentence-transformers) (11.1.0)\n",
            "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /usr/local/lib/python3.11/dist-packages (from spacy) (3.0.12)\n",
            "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from spacy) (1.0.5)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.11/dist-packages (from spacy) (1.0.12)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.11/dist-packages (from spacy) (2.0.11)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.11/dist-packages (from spacy) (3.0.9)\n",
            "Requirement already satisfied: thinc<8.3.0,>=8.2.2 in /usr/local/lib/python3.11/dist-packages (from spacy) (8.2.5)\n",
            "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /usr/local/lib/python3.11/dist-packages (from spacy) (1.1.3)\n",
            "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.11/dist-packages (from spacy) (2.5.1)\n",
            "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.11/dist-packages (from spacy) (2.0.10)\n",
            "Requirement already satisfied: weasel<0.5.0,>=0.1.0 in /usr/local/lib/python3.11/dist-packages (from spacy) (0.4.1)\n",
            "Requirement already satisfied: typer<1.0.0,>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from spacy) (0.15.1)\n",
            "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in /usr/local/lib/python3.11/dist-packages (from spacy) (2.10.6)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from spacy) (3.1.5)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from spacy) (75.1.0)\n",
            "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.11/dist-packages (from spacy) (3.5.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.1)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.11/dist-packages (from torch) (4.12.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch) (3.4.2)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch) (2024.10.0)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch)\n",
            "  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.4.127 (from torch)\n",
            "  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.4.127 (from torch)\n",
            "  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch)\n",
            "  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cublas-cu12==12.4.5.8 (from torch)\n",
            "  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cufft-cu12==11.2.1.3 (from torch)\n",
            "  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-curand-cu12==10.3.5.147 (from torch)\n",
            "  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch)\n",
            "  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch)\n",
            "  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch)\n",
            "  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: triton==3.1.0 in /usr/local/lib/python3.11/dist-packages (from torch) (3.1.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch) (1.3.0)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.11/dist-packages (from openai) (3.7.1)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.11/dist-packages (from openai) (1.9.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from openai) (0.28.1)\n",
            "Requirement already satisfied: jiter<1,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from openai) (0.8.2)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.11/dist-packages (from openai) (1.3.1)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.11/dist-packages (from nltk) (8.1.8)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.11/dist-packages (from nltk) (1.4.2)\n",
            "Requirement already satisfied: smart-open>=1.8.1 in /usr/local/lib/python3.11/dist-packages (from gensim) (7.1.0)\n",
            "Requirement already satisfied: cffi>=1.0 in /usr/local/lib/python3.11/dist-packages (from soundfile) (1.17.1)\n",
            "Requirement already satisfied: audioread>=2.1.9 in /usr/local/lib/python3.11/dist-packages (from librosa) (3.0.1)\n",
            "Requirement already satisfied: decorator>=4.3.0 in /usr/local/lib/python3.11/dist-packages (from librosa) (4.4.2)\n",
            "Requirement already satisfied: numba>=0.51.0 in /usr/local/lib/python3.11/dist-packages (from librosa) (0.60.0)\n",
            "Requirement already satisfied: pooch>=1.1 in /usr/local/lib/python3.11/dist-packages (from librosa) (1.8.2)\n",
            "Requirement already satisfied: soxr>=0.3.2 in /usr/local/lib/python3.11/dist-packages (from librosa) (0.5.0.post1)\n",
            "Requirement already satisfied: lazy-loader>=0.1 in /usr/local/lib/python3.11/dist-packages (from librosa) (0.4)\n",
            "Requirement already satisfied: msgpack>=1.0 in /usr/local/lib/python3.11/dist-packages (from librosa) (1.1.0)\n",
            "Collecting textsearch>=0.0.21 (from contractions)\n",
            "  Downloading textsearch-0.0.24-py2.py3-none-any.whl.metadata (1.2 kB)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.11/dist-packages (from anyio<5,>=3.5.0->openai) (3.10)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.11/dist-packages (from cffi>=1.0->soundfile) (2.22)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->openai) (2024.12.14)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->openai) (1.0.7)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.14.0)\n",
            "Requirement already satisfied: language-data>=1.2 in /usr/local/lib/python3.11/dist-packages (from langcodes<4.0.0,>=3.2.0->spacy) (1.3.0)\n",
            "Requirement already satisfied: llvmlite<0.44,>=0.43.0dev0 in /usr/local/lib/python3.11/dist-packages (from numba>=0.51.0->librosa) (0.43.0)\n",
            "Requirement already satisfied: platformdirs>=2.5.0 in /usr/local/lib/python3.11/dist-packages (from pooch>=1.1->librosa) (4.3.6)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.27.2 in /usr/local/lib/python3.11/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (2.27.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.4.1)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2.3.0)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn->sentence-transformers) (3.5.0)\n",
            "Requirement already satisfied: wrapt in /usr/local/lib/python3.11/dist-packages (from smart-open>=1.8.1->gensim) (1.17.2)\n",
            "Collecting anyascii (from textsearch>=0.0.21->contractions)\n",
            "  Downloading anyascii-0.3.2-py3-none-any.whl.metadata (1.5 kB)\n",
            "Collecting pyahocorasick (from textsearch>=0.0.21->contractions)\n",
            "  Downloading pyahocorasick-2.1.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (13 kB)\n",
            "Requirement already satisfied: blis<0.8.0,>=0.7.8 in /usr/local/lib/python3.11/dist-packages (from thinc<8.3.0,>=8.2.2->spacy) (0.7.11)\n",
            "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /usr/local/lib/python3.11/dist-packages (from thinc<8.3.0,>=8.2.2->spacy) (0.1.5)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0.0,>=0.3.0->spacy) (1.5.4)\n",
            "Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0.0,>=0.3.0->spacy) (13.9.4)\n",
            "Requirement already satisfied: cloudpathlib<1.0.0,>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from weasel<0.5.0,>=0.1.0->spacy) (0.20.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->spacy) (3.0.2)\n",
            "Requirement already satisfied: marisa-trie>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from language-data>=1.2->langcodes<4.0.0,>=3.2.0->spacy) (1.2.1)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy) (2.18.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy) (0.1.2)\n",
            "Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m4.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m73.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m60.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m41.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m1.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m6.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m11.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m7.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m5.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m67.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading contractions-0.1.73-py2.py3-none-any.whl (8.7 kB)\n",
            "Downloading textsearch-0.0.24-py2.py3-none-any.whl (7.6 kB)\n",
            "Downloading anyascii-0.3.2-py3-none-any.whl (289 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m289.9/289.9 kB\u001b[0m \u001b[31m20.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pyahocorasick-2.1.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (118 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m118.3/118.3 kB\u001b[0m \u001b[31m9.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: pyahocorasick, nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, anyascii, textsearch, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, contractions\n",
            "  Attempting uninstall: nvidia-nvjitlink-cu12\n",
            "    Found existing installation: nvidia-nvjitlink-cu12 12.5.82\n",
            "    Uninstalling nvidia-nvjitlink-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-nvjitlink-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-curand-cu12\n",
            "    Found existing installation: nvidia-curand-cu12 10.3.6.82\n",
            "    Uninstalling nvidia-curand-cu12-10.3.6.82:\n",
            "      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\n",
            "  Attempting uninstall: nvidia-cufft-cu12\n",
            "    Found existing installation: nvidia-cufft-cu12 11.2.3.61\n",
            "    Uninstalling nvidia-cufft-cu12-11.2.3.61:\n",
            "      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\n",
            "  Attempting uninstall: nvidia-cuda-runtime-cu12\n",
            "    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n",
            "    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-cupti-cu12\n",
            "    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cublas-cu12\n",
            "    Found existing installation: nvidia-cublas-cu12 12.5.3.2\n",
            "    Uninstalling nvidia-cublas-cu12-12.5.3.2:\n",
            "      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\n",
            "  Attempting uninstall: nvidia-cusparse-cu12\n",
            "    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\n",
            "    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\n",
            "      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\n",
            "  Attempting uninstall: nvidia-cudnn-cu12\n",
            "    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n",
            "    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n",
            "      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n",
            "  Attempting uninstall: nvidia-cusolver-cu12\n",
            "    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\n",
            "    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\n",
            "      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\n",
            "Successfully installed anyascii-0.3.2 contractions-0.1.73 nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127 pyahocorasick-2.1.0 textsearch-0.0.24\n"
          ]
        }
      ],
      "source": [
        "pip install transformers sentence-transformers spacy numpy pandas torch openai nltk gensim soundfile librosa contractions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "dzDwh18zRq-B",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dzDwh18zRq-B",
        "outputId": "6ac8f3b2-b2ac-4bfd-eeeb-dc4d50205476"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pylangacq\n",
            "  Downloading pylangacq-0.19.1-py3-none-any.whl.metadata (5.9 kB)\n",
            "Requirement already satisfied: python-dateutil>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from pylangacq) (2.8.2)\n",
            "Requirement already satisfied: requests>=2.18.0 in /usr/local/lib/python3.11/dist-packages (from pylangacq) (2.32.3)\n",
            "Requirement already satisfied: tabulate>=0.8.9 in /usr/local/lib/python3.11/dist-packages (from tabulate[widechars]>=0.8.9->pylangacq) (0.9.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.0.0->pylangacq) (1.17.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.18.0->pylangacq) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.18.0->pylangacq) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.18.0->pylangacq) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.18.0->pylangacq) (2024.12.14)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.11/dist-packages (from tabulate[widechars]>=0.8.9->pylangacq) (0.2.13)\n",
            "Downloading pylangacq-0.19.1-py3-none-any.whl (85 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m85.2/85.2 kB\u001b[0m \u001b[31m5.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: pylangacq\n",
            "Successfully installed pylangacq-0.19.1\n",
            "Requirement already satisfied: pylangacq in /usr/local/lib/python3.11/dist-packages (0.19.1)\n",
            "Requirement already satisfied: python-dateutil>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from pylangacq) (2.8.2)\n",
            "Requirement already satisfied: requests>=2.18.0 in /usr/local/lib/python3.11/dist-packages (from pylangacq) (2.32.3)\n",
            "Requirement already satisfied: tabulate>=0.8.9 in /usr/local/lib/python3.11/dist-packages (from tabulate[widechars]>=0.8.9->pylangacq) (0.9.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.0.0->pylangacq) (1.17.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.18.0->pylangacq) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.18.0->pylangacq) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.18.0->pylangacq) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.18.0->pylangacq) (2024.12.14)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.11/dist-packages (from tabulate[widechars]>=0.8.9->pylangacq) (0.2.13)\n"
          ]
        }
      ],
      "source": [
        "!pip install pylangacq\n",
        "import pylangacq\n",
        "import os\n",
        "import re\n",
        "import pandas as pd\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "!pip install --upgrade pylangacq"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "HZ7-oS2eYAYa",
      "metadata": {
        "id": "HZ7-oS2eYAYa"
      },
      "outputs": [],
      "source": [
        "os.chdir(\"/content/drive/MyDrive/OneDrive/DementiaBank/Pitt/Pitt/Dementia/sentence/\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "PORzxOovorkU",
      "metadata": {
        "id": "PORzxOovorkU"
      },
      "source": [
        "##0.Check the file"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "t7XqoASja8Ws",
      "metadata": {
        "id": "t7XqoASja8Ws",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6c9aca62-6d47-4570-daaa-b0c9b167e720"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "File names: ['(YB)Sentence_annot_minor_list_.ipynb', '(YB)annot_major_sentence_.ipynb', '.ipynb_checkpoints', '001-0.cha', '001-0.mp3', '001-0_cleaned.txt', '001-0_cleaned_with_filler.txt', '001-0_cleaned_with_pause.txt', '001-0_cleaned_with_pause_and_correction.txt', '001-0_cleaned_with_pause_and_fillers.txt', '001-0_cleaned_with_pause_fillers_selfcorrection.txt', '001-2.cha', '001-2.mp3', '001-2.txt', '003-0.cha', '003-0.mp3', '003-0.txt', '003-0_cleaned_final.txt', '003-0_cleaned_with_filler.txt', '003-0_cleaned_with_filler_and_markers.txt', '003-0_cleaned_with_major_markers.txt', '005-0.cha', '005-0.mp3', '005-2.cha', '005-2.mp3', '005-2.txt', '007-0.cha', '007-0.mp3', '007-1.cha', '007-1.mp3', '007-3.cha', '007-3.mp3', '007-3.txt', '010-0.cha', '010-1.cha', '010-2.cha', '010-3.cha', '010-4.cha', '016-0.cha', '016-1.cha', '016-3.cha', '016-4.cha', '018-0.cha', '023-0.cha', '024-1.cha', '024-2.cha', '029-0.cha', '030-0.cha', '030-1.cha', '033-0.cha', '033-1.cha', '033-2.cha', '033-3.cha', '033-4.cha', '035-0.cha', '035-1.cha', '039-0.cha', '043-0.cha', '046-0.cha', '046-2.cha', '049-0.cha', '049-1.cha', '049-3.cha', '050-0.cha', '051-0.cha', '051-1.cha', '051-2.cha', '051-3.cha', '053-1.cha', '057-1.cha', '057-2.cha', '058-0.cha', '058-1.cha', '058-3.cha', '061-0.cha', '061-1.cha', '065-0.cha', '065-1.cha', '065-2.cha', '067-1.cha', '067-2.cha', '070-2.cha', '078-0.cha', '091-0.cha', '091-1.cha', '091-2.cha', '094-1.cha', '094-2.cha', '094-3.cha', '120-1.cha', '120-2.cha', '120-3.cha', '122-1.cha', '125-0.cha', '134-0.cha', '134-1.cha', '148-0.cha', '154-0.cha', '154-1.cha', '157-0.cha', '157-1.cha', '157-2.cha', '164-1.cha', '164-3.cha', '168-1.cha', '172-1.cha', '172-2.cha', '172-3.cha', '178-0.cha', '181-0.cha', '181-1.cha', '181-2.cha', '181-3.cha', '183-0.cha', '183-1.cha', '183-3.cha', '184-0.cha', '184-1.cha', '184-2.cha', '203-0.cha', '203-1.cha', '206-0.cha', '207-0.cha', '212-0.cha', '212-1.cha', '212-2.cha', '212-3.cha', '213-1.cha', '213-2.cha', '213-3.cha', '216-0.cha', '216-1.cha', '220-1.cha', '221-0.cha', '221-2.cha', '221-3.cha', '222-0.cha', '222-1.cha', '223-0.cha', '223-1.cha', '234-0.cha', '235-0.cha', '235-2.cha', '236-0.cha', '237-1.cha', '237-2.cha', '244-0.cha', '247-0.cha', '252-0.cha', '252-2.cha', '257-2.cha', '260-1.cha', '260-2.cha', '264-0.cha', '268-0.cha', '269-0.cha', '269-1.cha', '270-0.cha', '271-2.cha', '279-0.cha', '279-1.cha', '282-2.cha', '283-0.cha', '283-1.cha', '291-1.cha', '291-2.cha', '293-1.cha', '306-0.cha', '310-0.cha', '311-0.cha', '319-0.cha', '325-0.cha', '325-1.cha', '329-0.cha', '334-1.cha', '338-0.cha', '339-0.cha', '341-0.cha', '342-0.cha', '342-1.cha', '343-0.cha', '346-0.cha', '349-1.cha', '350-0.cha', '350-1.cha', '354-0.cha', '355-0.cha', '355-1.cha', '356-0.cha', '356-1.cha', '357-0.cha', '358-0.cha', '358-1.cha', '360-0.cha', '361-0.cha', '362-1.cha', '368-0.cha', '369-0.cha', '381-0.cha', '381-1.cha', '450-1.cha', '458-0.cha', '461-0.cha', '465-0.cha', '466-0.cha', '468-0.cha', '470-1.cha', '471-0.cha', '472-0.cha', '474-0.cha', '476-0.cha', '488-0.cha', '492-0.cha', '497-0.cha', '508-1.cha', '511-0.cha', '515-1.cha', '527-1.cha', '528-0.cha', '529-0.cha', '544-0.cha', '551-0.cha', '559-0.cha', '562-0.cha', '563-0.cha', '573-0.cha', '578-0.cha', '580-0.cha', '581-0.cha', '585-0.cha', '587-0.cha', '592-0.cha', '594-0.cha', '595-0.cha', '598-0.cha', '601-0.cha', '607-0.cha', '609-0.cha', '610-0.cha', '615-0.cha', '620-0.cha', '624-0.cha', '635-0.cha', '636-0.cha', '639-0.cha', '640-0.cha', '650-0.cha', '656-0.cha', '657-0.cha', '663-0.cha', '672-0.cha', '674-0.cha', '681-0.cha', '689-0.cha', '698-0.cha', '702-0.cha', '703-0.cha', '704-0.cha', '705-0.cha', '707-0.cha', '711-0.cha', 'Sentence_with_Timestamps_and_PAR_INV_Counts.xlsx', 'annotations_major_sentence.xlsx', 'annotations_minor_sentence.xlsx', 'language_features.xlsx', 'summary_results.csv']\n"
          ]
        }
      ],
      "source": [
        "files = os.listdir()\n",
        "files.sort()\n",
        "subjects = set()\n",
        "\n",
        "for file in files :\n",
        "    subjects.add(file[:-6])\n",
        "\n",
        "subjects = list(subjects)\n",
        "subjects.sort()\n",
        "print(\"File names:\", files)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "t6N0_l5-IhAL",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t6N0_l5-IhAL",
        "outputId": "f751d309-6e80-48e4-af1e-b7c1c4a61903"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "@UTF8\n",
            "@PID:\t11312/t-00016996-1\n",
            "@Begin\n",
            "@Languages:\teng\n",
            "@Participants:\tPAR Participant, INV Investigator\n",
            "@ID:\teng|Pitt|PAR|57;|male|ProbableAD||Participant|18||\n",
            "@ID:\teng|Pitt|INV|||||Investigator|||\n",
            "@Media:\t001-0, audio\n",
            "*INV:\tthe first word is pencil@q . \u00150_2693\u0015\n",
            "%mor:\tdet:art|the adj|first n|word cop|be&3S meta|pencil .\n",
            "%gra:\t1|3|DET 2|3|MOD 3|4|SUBJ 4|0|ROOT 5|4|PRED 6|4|PUNCT\n",
            "*PAR:\tI wrote with my pencil . \u00152693_5448\u0015\n",
            "%mor:\tpro:sub|I v|write&PAST prep|with det:poss|my n|pencil .\n",
            "%gra:\t1|2|SUBJ 2|0|ROOT 3|2|JCT 4|5|DET 5|3|POBJ 6|2|PUNCT\n",
            "*INV:\tthe next word is tree@q . \u00155448_10366\u0015\n",
            "%mor:\tdet:art|the adj|next n|word cop|be&3S meta|tree .\n",
            "%gra:\t1|3|DET 2|3|MOD 3|4|SUBJ 4|0|ROOT 5|4|PRED 6|4|PUNCT\n",
            "*PAR:\t<the tree> [/] the tree is beautiful . \u001510366_16980\u0015\n",
            "%mor:\tdet:art|the n|tree cop|be&3S adj|beautiful .\n",
            "%gra:\t1|2|DET 2|3|SUBJ 3|0|ROOT 4|3|PRED 5|3|PUNCT\n",
            "*INV:\tnow I've got two words . \u001516980_20793\u0015\n",
            "%mor:\tadv|now pro:sub|I~aux|have part|get&PASTP det:num|two n|word-PL .\n",
            "%gra:\t1|4|JCT 2|4|SUBJ 3|4|AUX 4|0|ROOT 5|6|QUANT 6|4|OBJ 7|4|PUNCT\n",
            "*INV:\tokay . \u001520793_21555\u0015\n",
            "%mor:\tco|okay .\n",
            "%gra:\t1|0|INCROOT 2|1|PUNCT\n",
            "*INV:\tI want you to put both words into a brief sentence . \u001521555_25385\u0015\n",
            "%mor:\tpro:sub|I v|want pro:per|you inf|to v|put&ZERO qn|both n|word-PL\n",
            "\tprep|into det:art|a adj|brief n|sentence .\n",
            "%gra:\t1|2|SUBJ 2|0|ROOT 3|2|OBJ 4|5|INF 5|2|COMP 6|7|QUANT 7|5|OBJ 8|5|JCT\n",
            "\t9|11|DET 10|11|MOD 11|8|POBJ 12|2|PUNCT\n",
            "*INV:\tdon't worry about the word order . \u001525385_26864\u0015\n",
            "%mor:\tmod|do~neg|not v|worry prep|about det:art|the n|word n|order .\n",
            "%gra:\t1|3|AUX 2|1|NEG 3|0|ROOT 4|3|JCT 5|7|DET 6|7|MOD 7|4|POBJ 8|3|PUNCT\n",
            "*INV:\tyou can use them in any order . \u001526864_28747\u0015\n",
            "%mor:\tpro:per|you mod|can v|use pro:obj|them prep|in qn|any n|order .\n",
            "%gra:\t1|3|SUBJ 2|3|AUX 3|0|ROOT 4|3|OBJ 5|3|JCT 6|7|QUANT 7|5|POBJ 8|3|PUNCT\n",
            "*INV:\tbut use both words in one sentence . \u001528639_31531\u0015\n",
            "%mor:\tconj|but n|use qn|both n|word-PL prep|in det:num|one n|sentence .\n",
            "%gra:\t1|0|INCROOT 2|1|COORD 3|4|QUANT 4|2|OBJ 5|4|NJCT 6|7|QUANT 7|5|POBJ\n",
            "\t8|1|PUNCT\n",
            "*INV:\tokay . \u001531531_32171\u0015\n",
            "%mor:\tco|okay .\n",
            "%gra:\t1|0|INCROOT 2|1|PUNCT\n",
            "*INV:\tchild@q hospital@q . \u001532171_34693\u0015\n",
            "%mor:\tmeta|child meta|hospital .\n",
            "%gra:\t1|0|INCROOT 2|1|ENUM 3|1|PUNCT\n",
            "*PAR:\tthe child was taken to the hospital . \u001534693_38490\u0015\n",
            "%mor:\tdet:art|the n|child aux|be&PAST&13S part|take&PASTP prep|to\n",
            "\tdet:art|the n|hospital .\n",
            "%gra:\t1|2|DET 2|4|SUBJ 3|4|AUX 4|0|ROOT 5|4|JCT 6|7|DET 7|5|POBJ 8|4|PUNCT\n",
            "*INV:\tokay . \u001538490_44325\u0015\n",
            "%mor:\tco|okay .\n",
            "%gra:\t1|0|INCROOT 2|1|PUNCT\n",
            "*INV:\tthe next two words are cold@q winter@q . \u001544325_49165\u0015\n",
            "%mor:\tdet:art|the adj|next det:num|two n|word-PL cop|be&PRES meta|cold\n",
            "\tmeta|winter .\n",
            "%gra:\t1|4|DET 2|4|MOD 3|4|QUANT 4|5|SUBJ 5|0|ROOT 6|5|PRED 7|5|PRED 8|5|PUNCT\n",
            "*PAR:\t(.) I can't think of any &-uh right now . [+ exc] \u001549165_63856\u0015\n",
            "%mor:\tpro:sub|I mod|can~neg|not v|think prep|of qn|any adv|right adv|now\n",
            "\t.\n",
            "%gra:\t1|4|SUBJ 2|4|AUX 3|2|NEG 4|0|ROOT 5|4|JCT 6|8|QUANT 7|8|JCT 8|5|POBJ\n",
            "\t9|4|PUNCT\n",
            "*PAR:\tI &=clears:throat +... [+ exc] \u001563856_68339\u0015\n",
            "%mor:\tpro:sub|I +...\n",
            "%gra:\t1|0|INCROOT 2|1|PUNCT\n",
            "@End\n",
            "\n"
          ]
        }
      ],
      "source": [
        "with open('001-0.cha', 'r', encoding='utf-8') as file:\n",
        "    contents = file.read()\n",
        "\n",
        "print(contents)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ojm_OBEibCzS",
      "metadata": {
        "id": "ojm_OBEibCzS"
      },
      "source": [
        "# 1.Data- Prepocessing: Input the mark\n",
        "\n",
        "1. @ q >> meta\n",
        "2. Self-correction:\n",
        "\n",
        "example: <the tree> [/] the tree is beautiful.>> [the tree:self-correction] the tree is beautiful\n",
        "\n",
        "\n",
        "3. Replace &=clears:throat with [clears throat]\n",
        "\n",
        "4. Replace +... with [incomplete]:\n",
        "\n",
        "example: I &=clears:throat +... >> I [clears throat] [incomplete]\n",
        "\n",
        "\n",
        "5. filler word: [filler word: uh|um|er|ah|I don't know|you know]\n",
        "\n",
        "example: I can't think of any [filler: uh] right now"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "lGYGe47PSCJ2",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lGYGe47PSCJ2",
        "outputId": "b09e37a2-f5ac-44f5-8420-9aa4056a5750"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Utterance: *INV:\tthe first word is pencil[Meta] .\n",
            "Timestamp: 0_2693\n",
            "%mor: %mor:\tdet:art|the adj|first n|word cop|be&3S meta|pencil .\n",
            "%gra: %gra:\t1|3|DET 2|3|MOD 3|4|SUBJ 4|0|ROOT 5|4|PRED 6|4|PUNCT\n",
            "\n",
            "Utterance: *PAR:\tI wrote with my pencil .\n",
            "Timestamp: 2693_5448\n",
            "%mor: %mor:\tpro:sub|I v|write&PAST prep|with det:poss|my n|pencil .\n",
            "%gra: %gra:\t1|2|SUBJ 2|0|ROOT 3|2|JCT 4|5|DET 5|3|POBJ 6|2|PUNCT\n",
            "\n",
            "Utterance: *INV:\tthe next word is tree[Meta] .\n",
            "Timestamp: 5448_10366\n",
            "%mor: %mor:\tdet:art|the adj|next n|word cop|be&3S meta|tree .\n",
            "%gra: %gra:\t1|3|DET 2|3|MOD 3|4|SUBJ 4|0|ROOT 5|4|PRED 6|4|PUNCT\n",
            "\n",
            "Utterance: *PAR:\t[the tree:self-correction] the tree is beautiful .\n",
            "Timestamp: 10366_16980\n",
            "%mor: %mor:\tdet:art|the n|tree cop|be&3S adj|beautiful .\n",
            "%gra: %gra:\t1|2|DET 2|3|SUBJ 3|0|ROOT 4|3|PRED 5|3|PUNCT\n",
            "\n",
            "Utterance: *INV:\tnow I've got two words .\n",
            "Timestamp: 16980_20793\n",
            "%mor: %mor:\tadv|now pro:sub|I~aux|have part|get&PASTP det:num|two n|word-PL .\n",
            "%gra: %gra:\t1|4|JCT 2|4|SUBJ 3|4|AUX 4|0|ROOT 5|6|QUANT 6|4|OBJ 7|4|PUNCT\n",
            "\n",
            "Utterance: *INV:\tokay .\n",
            "Timestamp: 20793_21555\n",
            "%mor: %mor:\tco|okay .\n",
            "%gra: %gra:\t1|0|INCROOT 2|1|PUNCT\n",
            "\n",
            "Utterance: *INV:\tI want you to put both words into a brief sentence .\n",
            "Timestamp: 21555_25385\n",
            "%mor: %mor:\tpro:sub|I v|want pro:per|you inf|to v|put&ZERO qn|both n|word-PL\n",
            "%gra: %gra:\t1|2|SUBJ 2|0|ROOT 3|2|OBJ 4|5|INF 5|2|COMP 6|7|QUANT 7|5|OBJ 8|5|JCT\n",
            "\n",
            "Utterance: *INV:\tdon't worry about the word order .\n",
            "Timestamp: 25385_26864\n",
            "%mor: %mor:\tmod|do~neg|not v|worry prep|about det:art|the n|word n|order .\n",
            "%gra: %gra:\t1|3|AUX 2|1|NEG 3|0|ROOT 4|3|JCT 5|7|DET 6|7|MOD 7|4|POBJ 8|3|PUNCT\n",
            "\n",
            "Utterance: *INV:\tyou can use them in any order .\n",
            "Timestamp: 26864_28747\n",
            "%mor: %mor:\tpro:per|you mod|can v|use pro:obj|them prep|in qn|any n|order .\n",
            "%gra: %gra:\t1|3|SUBJ 2|3|AUX 3|0|ROOT 4|3|OBJ 5|3|JCT 6|7|QUANT 7|5|POBJ 8|3|PUNCT\n",
            "\n",
            "Utterance: *INV:\tbut use both words in one sentence .\n",
            "Timestamp: 28639_31531\n",
            "%mor: %mor:\tconj|but n|use qn|both n|word-PL prep|in det:num|one n|sentence .\n",
            "%gra: %gra:\t1|0|INCROOT 2|1|COORD 3|4|QUANT 4|2|OBJ 5|4|NJCT 6|7|QUANT 7|5|POBJ\n",
            "\n",
            "Utterance: *INV:\tokay .\n",
            "Timestamp: 31531_32171\n",
            "%mor: %mor:\tco|okay .\n",
            "%gra: %gra:\t1|0|INCROOT 2|1|PUNCT\n",
            "\n",
            "Utterance: *INV:\tchild[Meta] hospital[Meta] .\n",
            "Timestamp: 32171_34693\n",
            "%mor: %mor:\tmeta|child meta|hospital .\n",
            "%gra: %gra:\t1|0|INCROOT 2|1|ENUM 3|1|PUNCT\n",
            "\n",
            "Utterance: *PAR:\tthe child was taken to the hospital .\n",
            "Timestamp: 34693_38490\n",
            "%mor: %mor:\tdet:art|the n|child aux|be&PAST&13S part|take&PASTP prep|to\n",
            "%gra: %gra:\t1|2|DET 2|4|SUBJ 3|4|AUX 4|0|ROOT 5|4|JCT 6|7|DET 7|5|POBJ 8|4|PUNCT\n",
            "\n",
            "Utterance: *INV:\tokay .\n",
            "Timestamp: 38490_44325\n",
            "%mor: %mor:\tco|okay .\n",
            "%gra: %gra:\t1|0|INCROOT 2|1|PUNCT\n",
            "\n",
            "Utterance: *INV:\tthe next two words are cold[Meta] winter[Meta] .\n",
            "Timestamp: 44325_49165\n",
            "%mor: %mor:\tdet:art|the adj|next det:num|two n|word-PL cop|be&PRES meta|cold\n",
            "%gra: %gra:\t1|4|DET 2|4|MOD 3|4|QUANT 4|5|SUBJ 5|0|ROOT 6|5|PRED 7|5|PRED 8|5|PUNCT\n",
            "\n",
            "Utterance: *PAR:\t(.) I can't think of any [filler: uh] right now . [+ exc]\n",
            "Timestamp: 49165_63856\n",
            "%mor: %mor:\tpro:sub|I mod|can~neg|not v|think prep|of qn|any adv|right adv|now\n",
            "%gra: %gra:\t1|4|SUBJ 2|4|AUX 3|2|NEG 4|0|ROOT 5|4|JCT 6|8|QUANT 7|8|JCT 8|5|POBJ\n",
            "\n",
            "Utterance: *PAR:\tI [clears throat] [incomplete] [+ exc]\n",
            "Timestamp: 63856_68339\n",
            "%mor: %mor:\tpro:sub|I +...\n",
            "%gra: %gra:\t1|0|INCROOT 2|1|PUNCT\n",
            "\n"
          ]
        }
      ],
      "source": [
        "import re\n",
        "\n",
        "# Load file contents\n",
        "with open('001-0.cha', 'r', encoding='utf-8') as file:\n",
        "    contents = file.readlines()\n",
        "\n",
        "# Define filler words and phrases\n",
        "filler_words_pattern = r\"\\b(uh|um|er|ah|I don't know|you know|like|sort of|kind of|I guess)\\b\"\n",
        "\n",
        "# Data preprocessing function\n",
        "def preprocess_data(lines):\n",
        "    processed_data = []\n",
        "\n",
        "    for line in lines:\n",
        "        # Extracting utterance, %mor, %gra, and timestamp information\n",
        "        if line.startswith(\"*\"):\n",
        "            # Replace @q with [Pause]\n",
        "            utterance = re.sub(r\"@q\", \"[Meta]\", line)\n",
        "            # Replace &=clears:throat with [clears throat]\n",
        "            utterance = re.sub(r\"&=clears:throat\", \"[clears throat]\", utterance)\n",
        "\n",
        "            # Remove &- symbols\n",
        "            utterance = re.sub(r\"&-\", \"\", utterance)\n",
        "            # Replace +... with [incomplete]\n",
        "            utterance = re.sub(r\"\\+\\.{3}\", \"[incomplete]\", utterance)\n",
        "\n",
        "            # Format filler words\n",
        "            utterance = re.sub(filler_words_pattern, lambda m: f\"[filler: {m.group(0)}]\", utterance)\n",
        "\n",
        "            # Add [self-correction] for self-corrections, simplifying any repeat phrases\n",
        "            utterance = re.sub(r\"<(.*?)>\\s*\\[/\\]\", r\"[\\1:self-correction]\", utterance).strip()\n",
        "\n",
        "            # Extract timestamp\n",
        "            timestamp = re.search(r\"\u0015(\\d+_\\d+)\u0015\", line)\n",
        "            if timestamp:\n",
        "                timestamp = timestamp.group(1)\n",
        "                utterance = re.sub(r\"\u0015\\d+_\\d+\u0015\", \"\", utterance).strip()  # Clean up timestamp from the text\n",
        "\n",
        "            # Append the utterance and timestamp\n",
        "            processed_data.append({\"utterance\": utterance, \"timestamp\": timestamp})\n",
        "\n",
        "        elif line.startswith(\"%mor\") or line.startswith(\"%gra\"):\n",
        "            # Process %mor and %gra tags\n",
        "            tag = line.split(\":\")[0]\n",
        "            tag_data = re.sub(r\"@q\", \"[Pause]\", line).strip()\n",
        "            processed_data[-1][tag] = tag_data  # Add tag to last utterance entry\n",
        "\n",
        "    return processed_data\n",
        "\n",
        "# Apply preprocessing\n",
        "processed_data = preprocess_data(contents)\n",
        "\n",
        "# Display results\n",
        "for entry in processed_data:\n",
        "    print(f\"Utterance: {entry.get('utterance')}\")\n",
        "    print(f\"Timestamp: {entry.get('timestamp')}\")\n",
        "    print(f\"%mor: {entry.get('%mor', '')}\")\n",
        "    print(f\"%gra: {entry.get('%gra', '')}\")\n",
        "    print()  # Separator\n",
        "\n",
        "#  save to a new file\n",
        "with open('003-0_cleaned_with_filler.txt', 'w', encoding='utf-8') as cleaned_file:\n",
        "    for entry in processed_data:\n",
        "        cleaned_file.write(f\"Utterance: {entry.get('utterance')}\\n\")\n",
        "        cleaned_file.write(f\"Timestamp: {entry.get('timestamp')}\\n\")\n",
        "        cleaned_file.write(f\"%mor: {entry.get('%mor', '')}\\n\")\n",
        "        cleaned_file.write(f\"%gra: {entry.get('%gra', '')}\\n\\n\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "kW7NPz-wSQNN",
      "metadata": {
        "id": "kW7NPz-wSQNN"
      },
      "source": [
        "# Sentence construction\n",
        "• Available for both dementia group only\n",
        "\n",
        "• Task description: participant is given one or more words and asked to make up a simple sentence using those words; the words do not have to be used in the same order as they were presented\n",
        "\n",
        "• “pencil”, “tree”, “child, hospital”, “cold, winter”, “chair, doctor, sit”, “bureau, open, drawer”\n",
        "\n",
        "• Task-specific features\n",
        "\n",
        "Feature Cognitive construct\n",
        "\n",
        "1. Number of missing tasks for each person: N/A\n",
        "2. Number of correct complete sentences: Verbal expression\n",
        "3. Number of complete sentences not using the provided words: Verbal expression\n",
        "4. Number of incomplete sentences (not including a verb with a subject and/or object) Grammar, telegraphic speech\n",
        "5. Number of grammatical errors Grammar\n",
        "6. Number of repetitions of the presented words without forming a sentence Echolalia\n",
        "7. Number of repeated attempts to formulate a sentence for the same word(s) Verbal expression\n",
        "8. Number of filler words (e.g., um) Word-finding difficulties\n",
        "Mean speech rate Language"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "aEHsqe60ScQZ",
      "metadata": {
        "id": "aEHsqe60ScQZ"
      },
      "source": [
        "##1. Number of missing tasks for each person: N/A 6. Number of repetitions of the presented words without forming a sentence Echolalia\n",
        "\n",
        "This code checks if PAR has responded to tasks presented by INV using specified word groups. It first defines these word groups (e.g., pencil, tree, etc.) and sets up variables to track whether each group was presented (task_presented), responded to (task_responded), and if the response was a complete sentence (task_complete).\n",
        "\n",
        "The code then processes each entry in processed_data. For INV entries, it records presented groups in task_presented. For PAR entries, it checks if specified words are included and, if both a subject and verb are present, marks it as a complete response in task_complete.\n",
        "\n",
        "Finally, it identifies missing tasks (when INV presented but PAR did not respond) and creates a DataFrame showing if each word group was presented, responded to, marked as a missing task, and if the response was complete, providing an overview of PAR’s responses.\n",
        "\n",
        "\n",
        "To add the Echolalia column, we check for responses where PAR repeats the words presented by INV without forming a complete sentence. Specifically, if PAR uses only the provided words and the response lacks both a subject and a verb, it is marked as echolalia."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "NIpdwcuIg98b",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 237
        },
        "id": "NIpdwcuIg98b",
        "outputId": "09d58464-6ff6-44d1-e1cd-150e75b7c56f"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                  Words  INV ASK PAR Miss Word PAR Complete Sentence  \\\n",
              "0                pencil      Yes            No                   Yes   \n",
              "1                  tree      Yes            No                   Yes   \n",
              "2       child, hospital      Yes            No                   Yes   \n",
              "3          cold, winter      Yes           Yes                    No   \n",
              "4    chair, doctor, sit  INVALID       INVALID               INVALID   \n",
              "5  bureau, open, drawer  INVALID       INVALID               INVALID   \n",
              "\n",
              "  Echolalia   Result  \n",
              "0        No  Success  \n",
              "1        No  Success  \n",
              "2        No  Success  \n",
              "3        No     Fail  \n",
              "4   INVALID  INVALID  \n",
              "5   INVALID  INVALID  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-09e484d4-23ce-44d2-99b1-6bd2a9d0ccc8\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Words</th>\n",
              "      <th>INV ASK</th>\n",
              "      <th>PAR Miss Word</th>\n",
              "      <th>PAR Complete Sentence</th>\n",
              "      <th>Echolalia</th>\n",
              "      <th>Result</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>pencil</td>\n",
              "      <td>Yes</td>\n",
              "      <td>No</td>\n",
              "      <td>Yes</td>\n",
              "      <td>No</td>\n",
              "      <td>Success</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>tree</td>\n",
              "      <td>Yes</td>\n",
              "      <td>No</td>\n",
              "      <td>Yes</td>\n",
              "      <td>No</td>\n",
              "      <td>Success</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>child, hospital</td>\n",
              "      <td>Yes</td>\n",
              "      <td>No</td>\n",
              "      <td>Yes</td>\n",
              "      <td>No</td>\n",
              "      <td>Success</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>cold, winter</td>\n",
              "      <td>Yes</td>\n",
              "      <td>Yes</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>Fail</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>chair, doctor, sit</td>\n",
              "      <td>INVALID</td>\n",
              "      <td>INVALID</td>\n",
              "      <td>INVALID</td>\n",
              "      <td>INVALID</td>\n",
              "      <td>INVALID</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>bureau, open, drawer</td>\n",
              "      <td>INVALID</td>\n",
              "      <td>INVALID</td>\n",
              "      <td>INVALID</td>\n",
              "      <td>INVALID</td>\n",
              "      <td>INVALID</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-09e484d4-23ce-44d2-99b1-6bd2a9d0ccc8')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-09e484d4-23ce-44d2-99b1-6bd2a9d0ccc8 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-09e484d4-23ce-44d2-99b1-6bd2a9d0ccc8');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-312ab34f-a517-4b8e-be84-af9e61afdcb1\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-312ab34f-a517-4b8e-be84-af9e61afdcb1')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-312ab34f-a517-4b8e-be84-af9e61afdcb1 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "  <div id=\"id_cca4c231-16f6-4603-a57f-b6479010322c\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('df_missing_tasks')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_cca4c231-16f6-4603-a57f-b6479010322c button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('df_missing_tasks');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df_missing_tasks",
              "summary": "{\n  \"name\": \"df_missing_tasks\",\n  \"rows\": 6,\n  \"fields\": [\n    {\n      \"column\": \"Words\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 6,\n        \"samples\": [\n          \"pencil\",\n          \"tree\",\n          \"bureau, open, drawer\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"INV ASK\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          \"INVALID\",\n          \"Yes\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"PAR Miss Word\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 3,\n        \"samples\": [\n          \"No\",\n          \"Yes\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"PAR Complete Sentence\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 3,\n        \"samples\": [\n          \"Yes\",\n          \"No\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Echolalia\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          \"INVALID\",\n          \"No\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Result\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 3,\n        \"samples\": [\n          \"Success\",\n          \"Fail\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 8
        }
      ],
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Define expected word groups\n",
        "word_groups = {\n",
        "    \"pencil\": False,\n",
        "    \"tree\": False,\n",
        "    \"child, hospital\": False,\n",
        "    \"cold, winter\": False,\n",
        "    \"chair, doctor, sit\": False,\n",
        "    \"bureau, open, drawer\": False\n",
        "}\n",
        "\n",
        "# Initialize dictionaries to track presented tasks, responses, completeness, and echolalia\n",
        "task_presented = {group: False for group in word_groups.keys()}\n",
        "task_responded = {group: False for group in word_groups.keys()}\n",
        "task_complete = {group: False for group in word_groups.keys()}\n",
        "echolalia = {group: False for group in word_groups.keys()}\n",
        "missing_tasks = {}\n",
        "\n",
        "# Process the entries\n",
        "for entry in processed_data:\n",
        "    utterance = entry[\"utterance\"]\n",
        "    speaker = \"INV\" if utterance.startswith(\"*INV\") else \"PAR\"\n",
        "\n",
        "    for group_words in word_groups.keys():\n",
        "        group_list = group_words.split(\", \")\n",
        "\n",
        "        # Track task presented by INV\n",
        "        if speaker == \"INV\" and all(word in utterance for word in group_list):\n",
        "            task_presented[group_words] = True\n",
        "\n",
        "        # Track task response by PAR\n",
        "        elif speaker == \"PAR\" and all(word in utterance for word in group_list):\n",
        "            task_responded[group_words] = True\n",
        "\n",
        "            # Check if the sentence is complete (has both subject and root)\n",
        "            is_complete = \"SUBJ\" in entry.get(\"%gra\", \"\") and \"ROOT\" in entry.get(\"%gra\", \"\")\n",
        "            task_complete[group_words] = is_complete\n",
        "\n",
        "            # Check for echolalia: contains the group words but is not a complete sentence\n",
        "            if not is_complete:\n",
        "                echolalia[group_words] = True\n",
        "\n",
        "# Calculate missing tasks: presented by INV but not responded by PAR\n",
        "for group, presented in task_presented.items():\n",
        "    missing_tasks[group] = presented and not task_responded[group]\n",
        "\n",
        "# Convert results to a DataFrame with the additional 'Complete Sentence', 'Echolalia', and 'Result' columns\n",
        "df_missing_tasks = pd.DataFrame([\n",
        "    {\n",
        "        \"Words\": words,\n",
        "        \"INV ASK\": \"INVALID\" if not task_presented[words] else \"Yes\",\n",
        "        \"PAR Miss Word\": \"INVALID\" if not task_presented[words] else (\"Yes\" if missing else \"No\"),\n",
        "        \"PAR Complete Sentence\": \"INVALID\" if not task_presented[words] else (\"Yes\" if task_complete[words] else \"No\"),\n",
        "        \"Echolalia\": \"INVALID\" if not task_presented[words] else (\"Yes\" if echolalia[words] else \"No\"),\n",
        "        \"Result\": \"INVALID\" if not task_presented[words] else (\n",
        "            \"Fail\" if missing_tasks[words] or not task_complete[words] or echolalia[words] else \"Success\"\n",
        "        )\n",
        "    }\n",
        "    for words, missing in missing_tasks.items()\n",
        "])\n",
        "\n",
        "# Display the updated DataFrame\n",
        "df_missing_tasks\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "qW9GwSAyTxd0",
      "metadata": {
        "id": "qW9GwSAyTxd0"
      },
      "source": [
        "## 2,3,4 Number of correct complete sentences: Verbal expression/ Number of complete sentences not using the provided words: Verbal expression/Number of incomplete sentences (not including a verb with a subject and/or object) Grammar, telegraphic speech"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "OWpkYUYNVNmb",
      "metadata": {
        "id": "OWpkYUYNVNmb"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Initialize counters\n",
        "total_sentences = 0\n",
        "complete_correct_sentences = 0\n",
        "complete_without_words = 0\n",
        "incomplete_sentences = 0\n",
        "\n",
        "# Process each PAR entry to classify sentences\n",
        "for entry in processed_data:\n",
        "    utterance = entry[\"utterance\"]\n",
        "    if utterance.startswith(\"*PAR\"):\n",
        "        total_sentences += 1\n",
        "        contains_all_words = False\n",
        "        for group_words in word_groups.keys():\n",
        "            group_list = group_words.split(\", \")\n",
        "            if all(word in utterance for word in group_list):\n",
        "                contains_all_words = True\n",
        "                break\n",
        "\n",
        "        # Check if the sentence has both subject and root\n",
        "        is_complete = \"SUBJ\" in entry.get(\"%gra\", \"\") and \"ROOT\" in entry.get(\"%gra\", \"\")\n",
        "\n",
        "        # Classification\n",
        "        if is_complete and contains_all_words:\n",
        "            complete_correct_sentences += 1\n",
        "        elif is_complete and not contains_all_words:\n",
        "            complete_without_words += 1\n",
        "        else:\n",
        "            incomplete_sentences += 1\n",
        "\n",
        "# Failure Percent 추가 및 수정\n",
        "failure_percent = (incomplete_sentences / total_sentences * 100) if total_sentences > 0 else 0\n",
        "\n",
        "df_sentence_analysis = pd.DataFrame([{\n",
        "    \"PAR Total Sentences\": total_sentences,\n",
        "    \"PAR Complete + Correct Sentences\": complete_correct_sentences,\n",
        "    \"Complete Sentences Without Provided Words\": complete_without_words,\n",
        "    \"Incomplete Sentences\": incomplete_sentences,\n",
        "    \"Failure Percent\": f\"{failure_percent:.2f}%\"\n",
        "}])\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "YoMQWAA6Tmxl",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YoMQWAA6Tmxl",
        "outputId": "6f96208f-511f-48a9-e85d-b9b15bd6adc8"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(           Complete Sentences Without Provided Words\n",
              " 0  *PAR:\\t(.) I can't think of any [filler: uh] r...,\n",
              "                             Incomplete Sentences\n",
              " 0  *PAR:\\tI [clears throat] [incomplete] [+ exc])"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ],
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Initialize lists to store sentences for detailed output\n",
        "complete_without_words_sentences = []\n",
        "incomplete_sentences_list = []\n",
        "\n",
        "# Process each PAR entry to classify sentences and capture details\n",
        "for entry in processed_data:\n",
        "    utterance = entry[\"utterance\"]\n",
        "    if utterance.startswith(\"*PAR\"):\n",
        "        # Check if the sentence contains provided words and if it's complete\n",
        "        contains_all_words = False\n",
        "        for group_words in word_groups.keys():\n",
        "            group_list = group_words.split(\", \")\n",
        "            if all(word in utterance for word in group_list):\n",
        "                contains_all_words = True\n",
        "                break\n",
        "\n",
        "        # Check if the sentence has both subject and root\n",
        "        is_complete = \"SUBJ\" in entry.get(\"%gra\", \"\") and \"ROOT\" in entry.get(\"%gra\", \"\")\n",
        "\n",
        "        # Classification and storage of sentences\n",
        "        if is_complete and not contains_all_words:\n",
        "            complete_without_words_sentences.append(utterance)\n",
        "        elif not is_complete:\n",
        "            incomplete_sentences_list.append(utterance)\n",
        "\n",
        "# Create DataFrames to display the detailed sentence lists\n",
        "df_complete_without_words = pd.DataFrame({\n",
        "    \"Complete Sentences Without Provided Words\": complete_without_words_sentences\n",
        "})\n",
        "\n",
        "df_incomplete_sentences = pd.DataFrame({\n",
        "    \"Incomplete Sentences\": incomplete_sentences_list\n",
        "})\n",
        "\n",
        "# Display both DataFrames\n",
        "df_complete_without_words, df_incomplete_sentences\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.6"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}