{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 61,
      "id": "21c26932-5384-4893-8ff2-2289cc60135f",
      "metadata": {
        "id": "21c26932-5384-4893-8ff2-2289cc60135f"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import re\n",
        "import pandas as pd\n",
        "import csv"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install pylangacq"
      ],
      "metadata": {
        "id": "aVvThUfVhPVt",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f1598eb5-54d8-4a1a-9645-f1302d7313ec"
      },
      "id": "aVvThUfVhPVt",
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pylangacq in /usr/local/lib/python3.11/dist-packages (0.19.1)\n",
            "Requirement already satisfied: python-dateutil>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from pylangacq) (2.8.2)\n",
            "Requirement already satisfied: requests>=2.18.0 in /usr/local/lib/python3.11/dist-packages (from pylangacq) (2.32.3)\n",
            "Requirement already satisfied: tabulate>=0.8.9 in /usr/local/lib/python3.11/dist-packages (from tabulate[widechars]>=0.8.9->pylangacq) (0.9.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.0.0->pylangacq) (1.17.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.18.0->pylangacq) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.18.0->pylangacq) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.18.0->pylangacq) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.18.0->pylangacq) (2024.12.14)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.11/dist-packages (from tabulate[widechars]>=0.8.9->pylangacq) (0.2.13)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "1MCIQfXsg13b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6e6d12b2-cca4-43f5-86f0-5d3d803f13ea"
      },
      "id": "1MCIQfXsg13b",
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 64,
      "id": "906272bb-340a-41c8-ade4-1e2b42b9f3a8",
      "metadata": {
        "id": "906272bb-340a-41c8-ade4-1e2b42b9f3a8"
      },
      "outputs": [],
      "source": [
        "os.chdir(\"/content/drive/MyDrive/OneDrive/DementiaBank/Pitt/Pitt/Dementia/sentence\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 65,
      "id": "f5007dd7-b1c0-4bdb-b0e6-1d169c488862",
      "metadata": {
        "id": "f5007dd7-b1c0-4bdb-b0e6-1d169c488862"
      },
      "outputs": [],
      "source": [
        "# Define the folder containing .cha files\n",
        "folder_path = \"./cha_files\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 66,
      "id": "837a9440-9043-4a7c-96ba-5a8bb613c81f",
      "metadata": {
        "id": "837a9440-9043-4a7c-96ba-5a8bb613c81f"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import re\n",
        "import pandas as pd\n",
        "import pylangacq\n",
        "\n",
        "# Function to remove illegal characters for Excel\n",
        "def remove_illegal_characters(text):\n",
        "    \"\"\"\n",
        "    Remove characters that are not allowed in Excel.\n",
        "    \"\"\"\n",
        "    ILLEGAL_CHARACTERS_RE = re.compile(r'[\\000-\\010]|[\\013-\\014]|[\\016-\\037]')\n",
        "    return ILLEGAL_CHARACTERS_RE.sub(\"\", text)\n",
        "\n",
        "# Function to clean text and extract Time_Start and Time_End\n",
        "def clean_text_and_extract_time(text):\n",
        "    \"\"\"\n",
        "    Clean text and extract Time_Start and Time_End from the utterance.\n",
        "    \"\"\"\n",
        "    time_pattern = r'\\x15(\\d+)_(\\d+)\\x15'  # Pattern to match time stamps\n",
        "    match = re.search(time_pattern, text)\n",
        "    if match:\n",
        "        time_start, time_end = match.groups()  # Extract start and end times\n",
        "        text = re.sub(time_pattern, '', text).strip()  # Remove time stamps from text\n",
        "    else:\n",
        "        time_start, time_end = None, None\n",
        "    return text, time_start, time_end\n",
        "\n",
        "# Function to count annotations based on conditions\n",
        "def count_annotations(text):\n",
        "    \"\"\"\n",
        "    Count specific patterns based on the provided conditions.\n",
        "    \"\"\"\n",
        "    patterns = {\n",
        "        \"Incomplete sentences\": r\"\\+\\.\\.\\.\",  # Trailing off +...: Trailing off\n",
        "        \"Grammatical errors\": r\"\\[\\+ gram\\]\",  # Grammatical errors [+ gram]\n",
        "        \"filler words\": r\"@fp|&-\",  # Filler words @fp(Filler Words) , &- (Fillers)\n",
        "        \"repetitions\": r\"\\[/\\]\"  # Repetition\n",
        "    }\n",
        "    counts = {key: len(re.findall(pattern, text)) for key, pattern in patterns.items()}\n",
        "    return counts"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 60,
      "id": "890eb074-9a93-42d3-9048-0c6d4d811f03",
      "metadata": {
        "id": "890eb074-9a93-42d3-9048-0c6d4d811f03",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "81a8dd23-4196-4617-a169-a07c5d93f0e0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processing file: 164-3.cha\n",
            "Processing file: 172-3.cha\n",
            "Processing file: 067-1.cha\n",
            "Processing file: 057-2.cha\n",
            "Processing file: 212-1.cha\n",
            "Processing file: 049-3.cha\n",
            "Processing file: 183-0.cha\n",
            "Processing file: 283-1.cha\n",
            "Processing file: 342-0.cha\n",
            "Processing file: 094-1.cha\n",
            "Processing file: 125-0.cha\n",
            "Processing file: 216-1.cha\n",
            "Processing file: 010-0.cha\n",
            "Processing file: 319-0.cha\n",
            "Processing file: 338-0.cha\n",
            "Processing file: 058-0.cha\n",
            "Processing file: 283-0.cha\n",
            "Processing file: 051-1.cha\n",
            "Processing file: 010-2.cha\n",
            "Processing file: 252-2.cha\n",
            "Processing file: 035-1.cha\n",
            "Processing file: 183-1.cha\n",
            "Processing file: 046-0.cha\n",
            "Processing file: 181-0.cha\n",
            "Processing file: 010-4.cha\n",
            "Processing file: 341-0.cha\n",
            "Processing file: 154-1.cha\n",
            "Processing file: 157-2.cha\n",
            "Processing file: 257-2.cha\n",
            "Processing file: 181-2.cha\n",
            "Processing file: 051-2.cha\n",
            "Processing file: 043-0.cha\n",
            "Processing file: 213-1.cha\n",
            "Processing file: 164-1.cha\n",
            "Processing file: 237-2.cha\n",
            "Processing file: 157-1.cha\n",
            "Processing file: 306-0.cha\n",
            "Processing file: 078-0.cha\n",
            "Processing file: 222-1.cha\n",
            "Processing file: 065-0.cha\n",
            "Processing file: 270-0.cha\n",
            "Processing file: 325-0.cha\n",
            "Processing file: 339-0.cha\n",
            "Processing file: 053-1.cha\n",
            "Processing file: 039-0.cha\n",
            "Processing file: 168-1.cha\n",
            "Processing file: 203-0.cha\n",
            "Processing file: 183-3.cha\n",
            "Processing file: 184-0.cha\n",
            "Processing file: 134-1.cha\n",
            "Processing file: 221-0.cha\n",
            "Processing file: 067-2.cha\n",
            "Processing file: 223-0.cha\n",
            "Processing file: 325-1.cha\n",
            "Processing file: 120-2.cha\n",
            "Processing file: 293-1.cha\n",
            "Processing file: 206-0.cha\n",
            "Processing file: 018-0.cha\n",
            "Processing file: 282-2.cha\n",
            "Processing file: 220-1.cha\n",
            "Processing file: 203-1.cha\n",
            "Processing file: 007-0.cha\n",
            "Processing file: 024-1.cha\n",
            "Processing file: 213-2.cha\n",
            "Processing file: 120-3.cha\n",
            "Processing file: 310-0.cha\n",
            "Processing file: 279-0.cha\n",
            "Processing file: 058-3.cha\n",
            "Processing file: 237-1.cha\n",
            "Processing file: 222-0.cha\n",
            "Processing file: 035-0.cha\n",
            "Processing file: 236-0.cha\n",
            "Processing file: 005-0.cha\n",
            "Processing file: 061-1.cha\n",
            "Processing file: 244-0.cha\n",
            "Processing file: 154-0.cha\n",
            "Processing file: 269-0.cha\n",
            "Processing file: 058-1.cha\n",
            "Processing file: 024-2.cha\n",
            "Processing file: 311-0.cha\n",
            "Processing file: 050-0.cha\n",
            "Processing file: 016-4.cha\n",
            "Processing file: 342-1.cha\n",
            "Processing file: 181-1.cha\n",
            "Processing file: 207-0.cha\n",
            "Processing file: 279-1.cha\n",
            "Processing file: 003-0.cha\n",
            "Processing file: 291-1.cha\n",
            "Processing file: 260-1.cha\n",
            "Processing file: 172-1.cha\n",
            "Processing file: 030-0.cha\n",
            "Processing file: 216-0.cha\n",
            "Processing file: 065-2.cha\n",
            "Processing file: 049-0.cha\n",
            "Processing file: 212-3.cha\n",
            "Processing file: 184-1.cha\n",
            "Processing file: 023-0.cha\n",
            "Processing file: 184-2.cha\n",
            "Processing file: 091-1.cha\n",
            "Processing file: 007-3.cha\n",
            "Processing file: 094-3.cha\n",
            "Processing file: 178-0.cha\n",
            "Processing file: 065-1.cha\n",
            "Processing file: 329-0.cha\n",
            "Processing file: 070-2.cha\n",
            "Processing file: 334-1.cha\n",
            "Processing file: 269-1.cha\n",
            "Processing file: 057-1.cha\n",
            "Processing file: 212-2.cha\n",
            "Processing file: 148-0.cha\n",
            "Processing file: 051-0.cha\n",
            "Processing file: 213-3.cha\n",
            "Processing file: 033-2.cha\n",
            "Processing file: 343-0.cha\n",
            "Processing file: 264-0.cha\n",
            "Processing file: 235-2.cha\n",
            "Processing file: 010-1.cha\n",
            "Processing file: 016-3.cha\n",
            "Processing file: 049-1.cha\n",
            "Processing file: 252-0.cha\n",
            "Processing file: 033-1.cha\n",
            "Processing file: 212-0.cha\n",
            "Processing file: 016-1.cha\n",
            "Processing file: 001-2.cha\n",
            "Processing file: 091-0.cha\n",
            "Processing file: 234-0.cha\n",
            "Processing file: 172-2.cha\n",
            "Processing file: 271-2.cha\n",
            "Processing file: 235-0.cha\n",
            "Processing file: 094-2.cha\n",
            "Processing file: 010-3.cha\n",
            "Processing file: 030-1.cha\n",
            "Processing file: 157-0.cha\n",
            "Processing file: 029-0.cha\n",
            "Processing file: 016-0.cha\n",
            "Processing file: 033-0.cha\n",
            "Processing file: 120-1.cha\n",
            "Processing file: 061-0.cha\n",
            "Processing file: 221-3.cha\n",
            "Processing file: 046-2.cha\n",
            "Processing file: 005-2.cha\n",
            "Processing file: 247-0.cha\n",
            "Processing file: 134-0.cha\n",
            "Processing file: 268-0.cha\n",
            "Processing file: 223-1.cha\n",
            "Processing file: 007-1.cha\n",
            "Processing file: 091-2.cha\n",
            "Processing file: 260-2.cha\n",
            "Processing file: 033-4.cha\n",
            "Processing file: 051-3.cha\n",
            "Processing file: 291-2.cha\n",
            "Processing file: 033-3.cha\n",
            "Processing file: 122-1.cha\n",
            "Processing file: 221-2.cha\n",
            "Processing file: 181-3.cha\n",
            "Processing file: 640-0.cha\n",
            "Processing file: 620-0.cha\n",
            "Processing file: 381-0.cha\n",
            "Processing file: 349-1.cha\n",
            "Processing file: 674-0.cha\n",
            "Processing file: 472-0.cha\n",
            "Processing file: 527-1.cha\n",
            "Processing file: 573-0.cha\n",
            "Processing file: 703-0.cha\n",
            "Processing file: 624-0.cha\n",
            "Processing file: 551-0.cha\n",
            "Processing file: 354-0.cha\n",
            "Processing file: 587-0.cha\n",
            "Processing file: 355-0.cha\n",
            "Processing file: 610-0.cha\n",
            "Processing file: 595-0.cha\n",
            "Processing file: 497-0.cha\n",
            "Processing file: 358-0.cha\n",
            "Processing file: 585-0.cha\n",
            "Processing file: 663-0.cha\n",
            "Processing file: 594-0.cha\n",
            "Processing file: 350-0.cha\n",
            "Processing file: 607-0.cha\n",
            "Processing file: 636-0.cha\n",
            "Processing file: 609-0.cha\n",
            "Processing file: 711-0.cha\n",
            "Processing file: 598-0.cha\n",
            "Processing file: 346-0.cha\n",
            "Processing file: 355-1.cha\n",
            "Processing file: 592-0.cha\n",
            "Processing file: 368-0.cha\n",
            "Processing file: 361-0.cha\n",
            "Processing file: 515-1.cha\n",
            "Processing file: 511-0.cha\n",
            "Processing file: 461-0.cha\n",
            "Processing file: 562-0.cha\n",
            "Processing file: 492-0.cha\n",
            "Processing file: 356-1.cha\n",
            "Processing file: 698-0.cha\n",
            "Processing file: 563-0.cha\n",
            "Processing file: 581-0.cha\n",
            "Processing file: 704-0.cha\n",
            "Processing file: 369-0.cha\n",
            "Processing file: 635-0.cha\n",
            "Processing file: 358-1.cha\n",
            "Processing file: 528-0.cha\n",
            "Processing file: 362-1.cha\n",
            "Processing file: 476-0.cha\n",
            "Processing file: 559-0.cha\n",
            "Processing file: 650-0.cha\n",
            "Processing file: 465-0.cha\n",
            "Processing file: 672-0.cha\n",
            "Processing file: 466-0.cha\n",
            "Processing file: 350-1.cha\n",
            "Processing file: 615-0.cha\n",
            "Processing file: 705-0.cha\n",
            "Processing file: 450-1.cha\n",
            "Processing file: 681-0.cha\n",
            "Processing file: 529-0.cha\n",
            "Processing file: 458-0.cha\n",
            "Processing file: 360-0.cha\n",
            "Processing file: 580-0.cha\n",
            "Processing file: 381-1.cha\n",
            "Processing file: 601-0.cha\n",
            "Processing file: 657-0.cha\n",
            "Processing file: 639-0.cha\n",
            "Processing file: 707-0.cha\n",
            "Processing file: 544-0.cha\n",
            "Processing file: 356-0.cha\n",
            "Processing file: 474-0.cha\n",
            "Processing file: 468-0.cha\n",
            "Processing file: 656-0.cha\n",
            "Processing file: 471-0.cha\n",
            "Processing file: 689-0.cha\n",
            "Processing file: 488-0.cha\n",
            "Processing file: 357-0.cha\n",
            "Processing file: 578-0.cha\n",
            "Processing file: 470-1.cha\n",
            "Processing file: 508-1.cha\n",
            "Processing file: 001-0.cha\n",
            "Processing file: 702-0.cha\n",
            "Annotations with timestamps and PAR INV counts saved to Sentence_with_Timestamps.xlsx\n"
          ]
        }
      ],
      "source": [
        "# Define word groups for analysis\n",
        "word_groups = {\n",
        "    \"pencil\": [\"pencil\"],\n",
        "    \"tree\": [\"tree\"],\n",
        "    \"child, hospital\": [\"child\", \"hospital\"],\n",
        "    \"cold, winter\": [\"cold\", \"winter\"],\n",
        "    \"chair, doctor, sit\": [\"chair\", \"doctor\", \"sit\"],\n",
        "    \"bureau, open, drawer\": [\"bureau\", \"open\", \"drawer\"]\n",
        "}\n",
        "\n",
        "# Function to update INV-related sentences\n",
        "def update_inv_sentences(file_name, utterances):\n",
        "    \"\"\"\n",
        "    Update INV-related sentences for the current file.\n",
        "    \"\"\"\n",
        "    inv_sentences = {key: [] for key in word_groups.keys()}  # Collect INV sentences\n",
        "\n",
        "    for utterance in utterances:\n",
        "        if utterance.participant == 'INV':\n",
        "            raw_text = utterance.tiers.get('INV', '')\n",
        "            for group, words in word_groups.items():\n",
        "                if all(word in raw_text for word in words):\n",
        "                    inv_sentences[group].append(raw_text)\n",
        "\n",
        "    return inv_sentences\n",
        "\n",
        "# Function to process utterances and extract required metrics\n",
        "def extract_annotations_from_utterances(utterances, file_name, inv_sentences):\n",
        "    \"\"\"\n",
        "    Extract annotations, INV sentences, and word group analysis for PAR utterances.\n",
        "    \"\"\"\n",
        "    all_annotations = []\n",
        "\n",
        "    for utterance in utterances:\n",
        "        if utterance.participant == 'PAR':\n",
        "            raw_text = utterance.tiers.get('PAR', '')\n",
        "            cleaned_text, time_start, time_end = clean_text_and_extract_time(raw_text)\n",
        "\n",
        "            # Count annotations for this utterance\n",
        "            annotation_counts = count_annotations(cleaned_text)\n",
        "\n",
        "            # Compile the row for this utterance\n",
        "            row = {\n",
        "                \"file_name\": file_name,\n",
        "                \"participant\": utterance.participant,\n",
        "                \"utterance_text\": cleaned_text,\n",
        "                \"Time_Start\": time_start,\n",
        "                \"Time_End\": time_end,\n",
        "                **annotation_counts\n",
        "            }\n",
        "\n",
        "            # Add word group counts for PAR utterances\n",
        "            for group, words in word_groups.items():\n",
        "                row[f\"PAR_{group}_Count\"] = sum(cleaned_text.count(word) for word in words)\n",
        "                row[f\"INV_{group}_Sentences\"] = \"; \".join(inv_sentences[group]) if inv_sentences[group] else \"N/A\"\n",
        "\n",
        "            all_annotations.append(row)\n",
        "\n",
        "    return all_annotations\n",
        "\n",
        "\n",
        "def add_ask_columns(df):\n",
        "    ask_columns = {\n",
        "        \"INV_child, hospital_Sentences\": \"INV_child, hospital_ASK\",\n",
        "        \"INV_tree_Sentences\": \"INV_tree_ASK\",\n",
        "        \"INV_cold, winter_Sentences\": \"INV_cold, winter_ASK\",\n",
        "        \"INV_chair, doctor, sit_Sentences\": \"INV_chair, doctor, sit_ASK\",\n",
        "        \"INV_bureau, open, drawer_Sentences\": \"INV_bureau, open, drawer_ASK\"\n",
        "    }\n",
        "\n",
        "    for sentence_col, ask_col in ask_columns.items():\n",
        "        if sentence_col in df.columns:\n",
        "            df[ask_col] = df[sentence_col].apply(lambda x: \"ASK\" if x != \"N/A\" else \"INVALID\")\n",
        "\n",
        "    return df\n",
        "\n",
        "def add_answer_columns(df):\n",
        "    \"\"\"\n",
        "    Adds answer columns based on ASK conditions and word group counts.\n",
        "    \"\"\"\n",
        "    answer_columns = {\n",
        "        \"INV_child, hospital_ASK\": \"P_child, hospital_Answer\",\n",
        "        \"INV_tree_ASK\": \"P_tree_Answer\",\n",
        "        \"INV_cold, winter_ASK\": \"P_cold, winter_Answer\",\n",
        "        \"INV_chair, doctor, sit_ASK\": \"P_chair, doctor, sit Answer\",\n",
        "        \"INV_bureau, open, drawer_ASK\": \"P_bureau, open, drawerAnswer\"\n",
        "    }\n",
        "\n",
        "    for ask_col, answer_col in answer_columns.items():\n",
        "        if ask_col in df.columns:\n",
        "            df[answer_col] = \"INVALID\"\n",
        "\n",
        "            # if ASK> YES\n",
        "            ask_files = df[df[ask_col] == \"ASK\"][\"file_name\"].unique()\n",
        "\n",
        "            for file in ask_files:\n",
        "                subset = df[df[\"file_name\"] == file]\n",
        "                relevant_columns = [col for col in df.columns if col.startswith(\"PAR_\") and col.endswith(\"_Count\")]\n",
        "                total_counts = subset[relevant_columns].sum().sum()\n",
        "\n",
        "                if total_counts > 0:\n",
        "                    df.loc[df[\"file_name\"] == file, answer_col] = \"YES\"\n",
        "                else:\n",
        "                    df.loc[df[\"file_name\"] == file, answer_col] = \"NO\"\n",
        "\n",
        "    return df\n",
        "\n",
        "\n",
        "# Function to clean data before saving to Excel\n",
        "def clean_data_for_excel(data):\n",
        "    \"\"\"\n",
        "    Remove illegal characters from DataFrame columns.\n",
        "    \"\"\"\n",
        "    for column in data.columns:\n",
        "        if data[column].dtype == \"object\":  # Only clean string-type columns\n",
        "            data[column] = data[column].apply(lambda x: remove_illegal_characters(x) if isinstance(x, str) else x)\n",
        "    return data\n",
        "\n",
        "# Process all .cha files in the current folder\n",
        "def process_cha_files():\n",
        "    all_annotations = []\n",
        "\n",
        "    for file_name in os.listdir(\".\"):\n",
        "        if file_name.endswith(\".cha\"):\n",
        "            print(f\"Processing file: {file_name}\")\n",
        "            corpus = pylangacq.read_chat(file_name)\n",
        "            utterances = corpus.utterances()\n",
        "\n",
        "            inv_sentences = update_inv_sentences(file_name, utterances)\n",
        "            file_annotations = extract_annotations_from_utterances(utterances, file_name, inv_sentences)\n",
        "            all_annotations.extend(file_annotations)\n",
        "\n",
        "    df = pd.DataFrame(all_annotations)\n",
        "    df = clean_data_for_excel(df)\n",
        "\n",
        "# ✅ ASK\n",
        "    df = add_ask_columns(df)\n",
        "\n",
        "# ✅ Answer\n",
        "    df = add_answer_columns(df)\n",
        "    # Write to Excel\n",
        "    output_file = \"Sentence_with_Timestamps.xlsx\"\n",
        "    df.to_excel(output_file, index=False, engine='openpyxl')\n",
        "    print(f\"Annotations with timestamps and PAR INV counts saved to {output_file}\")\n",
        "\n",
        "# Run the processing function\n",
        "process_cha_files()"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.4"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}